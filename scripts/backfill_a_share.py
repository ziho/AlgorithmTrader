#!/usr/bin/env python3
"""
A è‚¡æ•°æ®æ‰¹é‡ä¸‹è½½å‘½ä»¤è¡Œå·¥å…·

æ”¯æŒ:
- daily: å…¨å¸‚åœºæ—¥çº¿ OHLCV
- daily_basic: æ¯æ—¥æŒ‡æ ‡ï¼ˆå¸‚å€¼/æ¢æ‰‹ç‡/PE/PBï¼‰
- adj_factor: å¤æƒå› å­

ç”¨æ³•:
    # ä¸‹è½½ daily_basic (å¢é‡ï¼Œä»ä¸Šæ¬¡æ–­ç‚¹ç»­ä¼ )
    python scripts/backfill_a_share.py daily_basic

    # ä¸‹è½½ adj_factor
    python scripts/backfill_a_share.py adj_factor

    # æŒ‡å®šæ—¥æœŸèŒƒå›´
    python scripts/backfill_a_share.py daily_basic --start 20210714 --end 20260212

    # å¢é‡æ›´æ–°ï¼ˆè‡ªåŠ¨æ£€æµ‹ä¸Šæ¬¡ä¸‹è½½åˆ°å“ªé‡Œï¼‰
    python scripts/backfill_a_share.py daily --incremental

    # æŸ¥çœ‹å½“å‰æ•°æ®çŠ¶æ€
    python scripts/backfill_a_share.py status
"""

import argparse
import asyncio
import sqlite3
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


def get_latest_completed_date(data_dir: Path, timeframe: str) -> str | None:
    """ä» checkpoint DB æŸ¥è¯¢æŸä¸ª timeframe æœ€åå®Œæˆçš„æ—¥æœŸ"""
    db_path = data_dir / "fetch_checkpoint.db"
    if not db_path.exists():
        return None

    conn = sqlite3.connect(db_path)
    try:
        cur = conn.execute(
            """
            SELECT MAX(year * 10000 + month * 100 + day)
            FROM download_progress
            WHERE exchange = 'a_tushare'
              AND symbol = '__ALL__'
              AND timeframe = ?
              AND status = 'completed'
            """,
            (timeframe,),
        )
        row = cur.fetchone()
        if row and row[0]:
            return str(row[0])
        return None
    finally:
        conn.close()


def get_status(data_dir: Path) -> dict:
    """è·å–æ‰€æœ‰æ•°æ®ç±»å‹çš„çŠ¶æ€"""
    db_path = data_dir / "fetch_checkpoint.db"
    status = {}

    if not db_path.exists():
        return {"1d": None, "daily_basic": None, "adj_factor": None}

    conn = sqlite3.connect(db_path)
    try:
        for tf in ["1d", "daily_basic", "adj_factor"]:
            cur = conn.execute(
                """
                SELECT
                    COUNT(*) FILTER (WHERE status = 'completed'),
                    COUNT(*) FILTER (WHERE status = 'failed'),
                    MIN(year * 10000 + month * 100 + day) FILTER (WHERE status = 'completed'),
                    MAX(year * 10000 + month * 100 + day) FILTER (WHERE status = 'completed')
                FROM download_progress
                WHERE exchange = 'a_tushare'
                  AND symbol = '__ALL__'
                  AND timeframe = ?
                """,
                (tf,),
            )
            row = cur.fetchone()
            status[tf] = {
                "completed_days": row[0] or 0,
                "failed_days": row[1] or 0,
                "first_date": str(row[2]) if row[2] else None,
                "last_date": str(row[3]) if row[3] else None,
            }
    finally:
        conn.close()

    return status


def print_status(data_dir: Path) -> None:
    """æ‰“å°æ•°æ®çŠ¶æ€"""
    status = get_status(data_dir)
    today = datetime.now().strftime("%Y%m%d")

    print("=" * 60)
    print("A è‚¡æ•°æ®çŠ¶æ€æ€»è§ˆ")
    print(f"ä»Šæ—¥: {today}")
    print("=" * 60)

    name_map = {
        "1d": "æ—¥çº¿ OHLCV (daily)",
        "daily_basic": "æ¯æ—¥æŒ‡æ ‡ (daily_basic)",
        "adj_factor": "å¤æƒå› å­ (adj_factor)",
    }

    for tf, info in status.items():
        name = name_map.get(tf, tf)
        print(f"\nğŸ“Š {name}")

        if info["completed_days"] == 0:
            print("   âŒ æœªä¸‹è½½ä»»ä½•æ•°æ®")
            continue

        print(f"   âœ… å·²å®Œæˆ: {info['completed_days']:,} ä¸ªäº¤æ˜“æ—¥")
        if info["failed_days"] > 0:
            print(f"   âš ï¸  å¤±è´¥: {info['failed_days']} ä¸ªäº¤æ˜“æ—¥")
        print(f"   ğŸ“… èŒƒå›´: {info['first_date']} â†’ {info['last_date']}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¢é‡æ›´æ–°
        if info["last_date"] and info["last_date"] < today:
            print(f"   ğŸ”„ å¾…æ›´æ–°: {info['last_date']} â†’ {today}")
        elif info["last_date"] == today:
            print("   âœ… å·²æ˜¯æœ€æ–°")

    print("\n" + "=" * 60)


async def run_backfill(
    data_type: str,
    start_date: str,
    end_date: str,
    data_dir: Path,
) -> None:
    """æ‰§è¡Œä¸‹è½½"""
    from src.data.fetcher.tushare_history import TushareHistoryFetcher

    fetcher = TushareHistoryFetcher(data_dir=data_dir)

    # è¿›åº¦å›è°ƒ
    last_pct = [-1.0]

    def on_progress(stats):
        pct = stats.progress
        # æ¯ 1% æ‰“å°ä¸€æ¬¡
        if int(pct) > int(last_pct[0]):
            last_pct[0] = pct
            eta_str = ""
            if stats.eta_seconds is not None:
                mins = stats.eta_seconds / 60
                if mins > 60:
                    eta_str = f" ETA {mins / 60:.1f}h"
                else:
                    eta_str = f" ETA {mins:.0f}min"

            done = stats.completed_days + stats.skipped_days
            print(
                f"\r  [{pct:5.1f}%] {done}/{stats.total_days} "
                f"rows={stats.total_rows:,} "
                f"fail={stats.failed_days}"
                f"{eta_str}",
                end="",
                flush=True,
            )

    fetcher.set_progress_callback(on_progress)

    print(f"å¼€å§‹ä¸‹è½½ {data_type}: {start_date} â†’ {end_date}")
    print(f"æ•°æ®ç›®å½•: {data_dir}")
    print("-" * 50)

    try:
        if data_type == "daily":
            stats = await fetcher.backfill_daily(
                start_date=start_date, end_date=end_date
            )
        elif data_type == "daily_basic":
            stats = await fetcher.backfill_daily_basic(
                start_date=start_date, end_date=end_date
            )
        elif data_type == "adj_factor":
            stats = await fetcher.backfill_adj_factor(
                start_date=start_date, end_date=end_date
            )
        else:
            print(f"âŒ æœªçŸ¥æ•°æ®ç±»å‹: {data_type}")
            return

        print()  # newline after progress
        print("-" * 50)
        print("âœ… ä¸‹è½½å®Œæˆ!")
        print(f"   å®Œæˆ: {stats.completed_days} æ—¥")
        print(f"   è·³è¿‡: {stats.skipped_days} æ—¥ (æ–­ç‚¹ç»­ä¼ )")
        print(f"   å¤±è´¥: {stats.failed_days} æ—¥")
        print(f"   æ€»è¡Œæ•°: {stats.total_rows:,}")
        print(f"   è€—æ—¶: {stats.elapsed_seconds:.1f} ç§’")

    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œå·²ä¿å­˜è¿›åº¦ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰")
    finally:
        await fetcher.close()


def main():
    parser = argparse.ArgumentParser(
        description="A è‚¡æ•°æ®æ‰¹é‡ä¸‹è½½å·¥å…· (Tushare)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s status                           # æŸ¥çœ‹æ•°æ®çŠ¶æ€
  %(prog)s daily_basic                      # ä¸‹è½½ daily_basic (å…¨é‡)
  %(prog)s adj_factor                       # ä¸‹è½½ adj_factor  (å…¨é‡)
  %(prog)s daily --incremental              # å¢é‡æ›´æ–°æ—¥çº¿ (è‡ªåŠ¨ç»­ä¼ )
  %(prog)s daily_basic --start 20210714     # ä»æŒ‡å®šæ—¥æœŸå¼€å§‹
  %(prog)s daily_basic --incremental        # å¢é‡æ›´æ–° daily_basic
""",
    )

    parser.add_argument(
        "type",
        choices=["daily", "daily_basic", "adj_factor", "status"],
        help="æ•°æ®ç±»å‹: daily(æ—¥çº¿), daily_basic(æ¯æ—¥æŒ‡æ ‡), adj_factor(å¤æƒå› å­), status(æŸ¥çœ‹çŠ¶æ€)",
    )
    parser.add_argument(
        "--start",
        default=None,
        help="å¼€å§‹æ—¥æœŸ YYYYMMDD (é»˜è®¤ 20180101)",
    )
    parser.add_argument(
        "--end",
        default=None,
        help="ç»“æŸæ—¥æœŸ YYYYMMDD (é»˜è®¤ä»Šå¤©)",
    )
    parser.add_argument(
        "--incremental",
        action="store_true",
        help="å¢é‡æ¨¡å¼: è‡ªåŠ¨ä»ä¸Šæ¬¡ä¸‹è½½çš„æœ€åæ—¥æœŸå¼€å§‹",
    )
    parser.add_argument(
        "--data-dir",
        default=str(PROJECT_ROOT / "data"),
        help="æ•°æ®ç›®å½• (é»˜è®¤ PROJECT_ROOT/data)",
    )

    args = parser.parse_args()
    data_dir = Path(args.data_dir)

    if args.type == "status":
        print_status(data_dir)
        return

    # ç¡®å®šæ—¥æœŸèŒƒå›´
    end_date = args.end or datetime.now().strftime("%Y%m%d")

    if args.incremental:
        # checkpoint timeframe key: 1d for daily, else same as type
        tf_key = "1d" if args.type == "daily" else args.type
        latest = get_latest_completed_date(data_dir, tf_key)
        if latest:
            # ä»æœ€åå®Œæˆæ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹
            from datetime import timedelta

            last_dt = datetime.strptime(latest, "%Y%m%d")
            next_dt = last_dt + timedelta(days=1)
            start_date = next_dt.strftime("%Y%m%d")
            print(f"ğŸ”„ å¢é‡æ¨¡å¼: ä¸Šæ¬¡å®Œæˆåˆ° {latest}, ä» {start_date} å¼€å§‹")

            if start_date > end_date:
                print("âœ… æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
                return
        else:
            start_date = args.start or "20180101"
            print(f"ğŸ“¦ é¦–æ¬¡ä¸‹è½½ï¼Œä» {start_date} å¼€å§‹")
    else:
        start_date = args.start or "20180101"

    asyncio.run(run_backfill(args.type, start_date, end_date, data_dir))


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
ğŸ“¥ å†å²æ•°æ®å¯¼å…¥è„šæœ¬

ä» Binance ä¸‹è½½å†å² K çº¿æ•°æ®å¹¶å†™å…¥ InfluxDB

åŠŸèƒ½:
1. ä» data.binance.vision ä¸‹è½½å†å²æ•°æ®
2. ä¿å­˜åˆ° Parquet å­˜å‚¨
3. å†™å…¥ InfluxDB (ä¾› Grafana å¯è§†åŒ–)

ä½¿ç”¨æ–¹å¼:
    # åœ¨ Docker ä¸­è¿è¡Œ
    docker-compose exec collector python scripts/import_historical_data.py
    
    # æŒ‡å®šå‚æ•°
    docker-compose exec collector python scripts/import_historical_data.py \
        --symbol BTCUSDT --timeframe 1h --start 2024-01-01 --end 2025-12-31
    
    # å¯¼å…¥å¤šä¸ªäº¤æ˜“å¯¹
    docker-compose exec collector python scripts/import_historical_data.py \
        --symbols BTCUSDT,ETHUSDT,BNBUSDT --timeframe 1m

æ•°æ®æº:
    https://data.binance.vision/
"""

import argparse
import asyncio
import sys
from datetime import UTC, datetime, timedelta
from decimal import Decimal
from pathlib import Path

import pandas as pd

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent


def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    print("\n" + "=" * 70)
    print("ğŸ“¥ AlgorithmTrader - å†å²æ•°æ®å¯¼å…¥")
    print("=" * 70)
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ•°æ®æº: Binance (data.binance.vision)")
    print("-" * 70)


def print_step(step: int, total: int, title: str):
    """æ‰“å°æ­¥éª¤"""
    print(f"\n{'='*70}")
    print(f"[{step}/{total}] {title}")
    print("-" * 70)


async def download_data(
    symbol: str,
    timeframe: str,
    start_date: datetime,
    end_date: datetime,
) -> pd.DataFrame:
    """ä» Binance ä¸‹è½½æ•°æ®"""
    from src.data.connectors.binance import BinanceConnector
    
    print(f"  ğŸ“Š äº¤æ˜“å¯¹: {symbol}")
    print(f"  â° æ—¶é—´æ¡†æ¶: {timeframe}")
    print(f"  ğŸ“… å¼€å§‹: {start_date.strftime('%Y-%m-%d')}")
    print(f"  ğŸ“… ç»“æŸ: {end_date.strftime('%Y-%m-%d')}")
    
    connector = BinanceConnector()
    
    try:
        df = await connector.download_historical_klines(
            symbol=symbol,
            timeframe=timeframe,
            start_date=start_date,
            end_date=end_date,
            market_type="spot",
        )
        
        if df.empty:
            print(f"  âš ï¸ æ— æ³•ä» Binance Vision ä¸‹è½½ï¼Œå°è¯• API...")
            # å°è¯•ä½¿ç”¨ API è·å–
            df = await _fetch_via_api(connector, symbol, timeframe, start_date, end_date)
        
        return df
    finally:
        await connector.close()


async def _fetch_via_api(
    connector,
    symbol: str,
    timeframe: str,
    start_date: datetime,
    end_date: datetime,
) -> pd.DataFrame:
    """é€šè¿‡ Binance API è·å–æ•°æ®"""
    from src.core.instruments import Exchange, Symbol
    from src.core.timeframes import Timeframe
    
    # è§£æäº¤æ˜“å¯¹
    if "/" in symbol:
        base, quote = symbol.split("/")
    else:
        # å‡è®¾æ˜¯ BTCUSDT æ ¼å¼
        if symbol.endswith("USDT"):
            base = symbol[:-4]
            quote = "USDT"
        elif symbol.endswith("BUSD"):
            base = symbol[:-4]
            quote = "BUSD"
        else:
            base = symbol[:-3]
            quote = symbol[-3:]
    
    sym = Symbol(exchange=Exchange.BINANCE, base=base, quote=quote)
    tf = Timeframe(timeframe)
    
    all_data = []
    current_start = start_date
    batch_count = 0
    
    print(f"\n  â³ ä» API é‡‡é›†æ•°æ®...")
    
    while current_start < end_date:
        try:
            df = await connector.fetch_ohlcv(
                symbol=sym,
                timeframe=tf,
                since=current_start,
                limit=1000,
            )
            
            if df.empty:
                break
            
            all_data.append(df)
            batch_count += 1
            
            last_ts = df["timestamp"].max()
            progress = (last_ts.timestamp() - start_date.timestamp()) / \
                      (end_date.timestamp() - start_date.timestamp()) * 100
            progress = min(progress, 100)
            
            if batch_count % 10 == 0:
                bars = sum(len(d) for d in all_data)
                print(f"  ğŸ“Š è¿›åº¦: {progress:5.1f}% | å·²é‡‡é›† {bars:6d} æ¡")
            
            # ç§»åŠ¨åˆ°ä¸‹ä¸€æ‰¹
            current_start = last_ts.to_pydatetime() + timedelta(minutes=1)
            
            await asyncio.sleep(0.2)  # é¿å…é™é¢‘
            
        except Exception as e:
            print(f"  âš ï¸ API é”™è¯¯: {e}")
            await asyncio.sleep(1)
            continue
    
    if all_data:
        result = pd.concat(all_data, ignore_index=True)
        result = result.drop_duplicates(subset=["timestamp"]).sort_values("timestamp").reset_index(drop=True)
        return result
    
    return pd.DataFrame()


def save_to_parquet(
    df: pd.DataFrame,
    symbol: str,
    timeframe: str,
) -> int:
    """ä¿å­˜åˆ° Parquet"""
    from src.core.instruments import Exchange, Symbol
    from src.core.timeframes import Timeframe
    from src.data.storage.parquet_store import ParquetStore
    
    # è§£æäº¤æ˜“å¯¹
    if "/" in symbol:
        base, quote = symbol.split("/")
    else:
        if symbol.endswith("USDT"):
            base = symbol[:-4]
            quote = "USDT"
        else:
            base = symbol[:-3]
            quote = symbol[-3:]
    
    sym = Symbol(exchange=Exchange.BINANCE, base=base, quote=quote)
    tf = Timeframe(timeframe)
    
    store = ParquetStore(base_path=PROJECT_ROOT / "data" / "parquet")
    rows = store.write(sym, tf, df)
    
    print(f"  âœ… å·²ä¿å­˜åˆ° Parquet: {rows} è¡Œ")
    print(f"     è·¯å¾„: {PROJECT_ROOT / 'data' / 'parquet' / 'binance' / f'{base}_{quote}'}")
    
    return rows


def write_to_influxdb(
    df: pd.DataFrame,
    symbol: str,
    timeframe: str,
) -> int:
    """å†™å…¥ InfluxDB"""
    from src.core.instruments import Exchange, Symbol
    from src.core.timeframes import Timeframe
    from src.data.storage.influx_store import InfluxStore
    
    # è§£æäº¤æ˜“å¯¹
    if "/" in symbol:
        base, quote = symbol.split("/")
    else:
        if symbol.endswith("USDT"):
            base = symbol[:-4]
            quote = "USDT"
        else:
            base = symbol[:-3]
            quote = symbol[-3:]
    
    sym = Symbol(exchange=Exchange.BINANCE, base=base, quote=quote)
    tf = Timeframe(timeframe)
    
    store = InfluxStore(async_write=False)  # åŒæ­¥å†™å…¥ç¡®ä¿æ•°æ®å†™å…¥
    
    try:
        points = store.write_ohlcv(sym, tf, df)
        store.flush()  # ç¡®ä¿åˆ·æ–°
        print(f"  âœ… å·²å†™å…¥ InfluxDB: {points} ä¸ªæ•°æ®ç‚¹")
        return points
    finally:
        store.close()


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¯¼å…¥ Binance å†å²æ•°æ®")
    parser.add_argument("--symbol", default="BTCUSDT", help="äº¤æ˜“å¯¹ (é»˜è®¤ BTCUSDT)")
    parser.add_argument("--symbols", help="å¤šä¸ªäº¤æ˜“å¯¹ï¼Œé€—å·åˆ†éš” (å¦‚ BTCUSDT,ETHUSDT)")
    parser.add_argument("--timeframe", default="1h", help="æ—¶é—´æ¡†æ¶ (é»˜è®¤ 1h)")
    parser.add_argument("--start", default="2024-01-01", help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--end", default="2025-12-31", help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--skip-parquet", action="store_true", help="è·³è¿‡ Parquet ä¿å­˜")
    parser.add_argument("--skip-influx", action="store_true", help="è·³è¿‡ InfluxDB å†™å…¥")
    args = parser.parse_args()
    
    print_banner()
    
    # è§£æäº¤æ˜“å¯¹
    if args.symbols:
        symbols = [s.strip() for s in args.symbols.split(",")]
    else:
        symbols = [args.symbol]
    
    timeframe = args.timeframe
    start_date = datetime.strptime(args.start, "%Y-%m-%d").replace(tzinfo=UTC)
    end_date = datetime.strptime(args.end, "%Y-%m-%d").replace(hour=23, minute=59, second=59, tzinfo=UTC)
    
    # å¦‚æœç»“æŸæ—¥æœŸåœ¨æœªæ¥ï¼Œè°ƒæ•´ä¸ºå½“å‰æ—¶é—´
    now = datetime.now(UTC)
    if end_date > now:
        end_date = now - timedelta(hours=1)  # ç•™ä¸€å°æ—¶ç¼“å†²
        print(f"  âš ï¸ ç»“æŸæ—¥æœŸè°ƒæ•´ä¸º: {end_date.strftime('%Y-%m-%d %H:%M')}")
    
    total_symbols = len(symbols)
    total_rows = 0
    total_influx_points = 0
    
    for i, symbol in enumerate(symbols, 1):
        print_step(i, total_symbols, f"å¤„ç† {symbol}")
        
        # ä¸‹è½½æ•°æ®
        print("\n  ğŸ“¥ ä¸‹è½½æ•°æ®...")
        df = await download_data(symbol, timeframe, start_date, end_date)
        
        if df.empty:
            print(f"  âŒ æœªè·å–åˆ° {symbol} çš„æ•°æ®")
            continue
        
        print(f"\n  âœ… ä¸‹è½½å®Œæˆ: {len(df)} æ¡æ•°æ®")
        print(f"     æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        
        # ä¿å­˜åˆ° Parquet
        if not args.skip_parquet:
            print("\n  ğŸ’¾ ä¿å­˜åˆ° Parquet...")
            try:
                save_to_parquet(df, symbol, timeframe)
            except Exception as e:
                print(f"  âš ï¸ Parquet ä¿å­˜å¤±è´¥: {e}")
        
        # å†™å…¥ InfluxDB
        if not args.skip_influx:
            print("\n  ğŸ“Š å†™å…¥ InfluxDB...")
            try:
                points = write_to_influxdb(df, symbol, timeframe)
                total_influx_points += points
            except Exception as e:
                print(f"  âš ï¸ InfluxDB å†™å…¥å¤±è´¥: {e}")
        
        total_rows += len(df)
    
    # å®Œæˆ
    print("\n" + "=" * 70)
    print("âœ… æ•°æ®å¯¼å…¥å®Œæˆï¼")
    print("=" * 70)
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"   å¤„ç†äº¤æ˜“å¯¹: {total_symbols} ä¸ª")
    print(f"   æ€»æ•°æ®é‡: {total_rows:,} æ¡")
    print(f"   InfluxDB æ•°æ®ç‚¹: {total_influx_points:,}")
    print(f"\nğŸ” æŸ¥çœ‹æ•°æ®:")
    print(f"   Grafana: http://localhost:3000 (admin/algorithmtrader123)")
    print(f"   InfluxDB: http://localhost:8086 (admin/algorithmtrader123)")
    print("=" * 70)
    
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

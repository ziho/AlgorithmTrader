# Phase 5: ç›‘æ§ä¸å‘Šè­¦

**é¢„è®¡æ—¶é—´**: 1å¤©  
**å‰ç½®æ¡ä»¶**: Phase 4 å®Œæˆï¼Œç­–ç•¥å›æµ‹æ­£å¸¸è¿è¡Œ  
**ç›®æ ‡**: å»ºç«‹å®Œæ•´çš„ç³»ç»Ÿç›‘æ§ã€æ—¥å¿—èšåˆå’Œå‘Šè­¦æœºåˆ¶

## æ­¥éª¤æ¸…å•

### 5.1 åˆ›å»ºç›‘æ§æ¨¡å—

#### ç›®å½•ç»“æ„
```bash
mkdir -p apps/monitoring
```

#### å¥åº·æ£€æŸ¥ç»„ä»¶

**apps/monitoring/health_check.py**
```python
"""
ç³»ç»Ÿå¥åº·æ£€æŸ¥æ¨¡å—
ç›‘æ§å„ä¸ªç»„ä»¶çš„è¿è¡ŒçŠ¶æ€
"""
import os
import time
import json
import redis
import psycopg2
import requests
from datetime import datetime, timedelta
from influxdb_client import InfluxDBClient
from typing import Dict, List, Optional
import logging

class HealthChecker:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.redis_client = redis.Redis.from_url(os.getenv('REDIS_URL'))
        self.pg_conn_string = os.getenv('POSTGRES_URL')
        self.influx_client = InfluxDBClient(
            url=os.getenv('INFLUXDB_URL'),
            token=os.getenv('INFLUXDB_ADMIN_TOKEN'),
            org=os.getenv('INFLUXDB_ORG')
        )
        
    def check_redis(self) -> Dict:
        """æ£€æŸ¥Redisè¿æ¥çŠ¶æ€"""
        try:
            start_time = time.time()
            self.redis_client.ping()
            latency = (time.time() - start_time) * 1000
            
            info = self.redis_client.info()
            return {
                'status': 'healthy',
                'latency_ms': round(latency, 2),
                'memory_used': info.get('used_memory_human'),
                'connected_clients': info.get('connected_clients')
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }
    
    def check_postgres(self) -> Dict:
        """æ£€æŸ¥PostgreSQLè¿æ¥çŠ¶æ€"""
        try:
            start_time = time.time()
            conn = psycopg2.connect(self.pg_conn_string)
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.fetchone()
            latency = (time.time() - start_time) * 1000
            
            cursor.execute("SELECT count(*) FROM pg_stat_activity")
            active_connections = cursor.fetchone()[0]
            
            cursor.close()
            conn.close()
            
            return {
                'status': 'healthy',
                'latency_ms': round(latency, 2),
                'active_connections': active_connections
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }
    
    def check_influxdb(self) -> Dict:
        """æ£€æŸ¥InfluxDBè¿æ¥çŠ¶æ€"""
        try:
            start_time = time.time()
            health = self.influx_client.health()
            latency = (time.time() - start_time) * 1000
            
            # æ£€æŸ¥æœ€è¿‘æ•°æ®
            query = f'''
                from(bucket: "{os.getenv('INFLUXDB_BUCKET')}")
                |> range(start: -1h)
                |> filter(fn: (r) => r._measurement == "crypto_ohlcv_1m")
                |> count()
            '''
            tables = self.influx_client.query_api().query(query)
            
            recent_data_points = 0
            for table in tables:
                for record in table.records:
                    recent_data_points += record.get_value()
            
            return {
                'status': 'healthy' if health.status == 'pass' else 'unhealthy',
                'latency_ms': round(latency, 2),
                'recent_data_points': recent_data_points,
                'influx_status': health.status
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }
    
    def check_grafana(self) -> Dict:
        """æ£€æŸ¥Grafanaè¿æ¥çŠ¶æ€"""
        try:
            start_time = time.time()
            response = requests.get(
                f"http://grafana:{os.getenv('GRAFANA_PORT', 3000)}/api/health",
                timeout=5
            )
            latency = (time.time() - start_time) * 1000
            
            return {
                'status': 'healthy' if response.status_code == 200 else 'unhealthy',
                'latency_ms': round(latency, 2),
                'response_code': response.status_code
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e)
            }
    
    def check_data_freshness(self) -> Dict:
        """æ£€æŸ¥æ•°æ®æ–°é²œåº¦"""
        try:
            query = f'''
                from(bucket: "{os.getenv('INFLUXDB_BUCKET')}")
                |> range(start: -24h)
                |> filter(fn: (r) => r._measurement == "crypto_ohlcv_1m")
                |> last()
            '''
            tables = self.influx_client.query_api().query(query)
            
            latest_timestamp = None
            for table in tables:
                for record in table.records:
                    timestamp = record.get_time()
                    if not latest_timestamp or timestamp > latest_timestamp:
                        latest_timestamp = timestamp
            
            if latest_timestamp:
                age_minutes = (datetime.now(latest_timestamp.tzinfo) - latest_timestamp).total_seconds() / 60
                is_fresh = age_minutes < 60  # æ•°æ®ä¸è¶…è¿‡1å°æ—¶ç®—æ–°é²œ
                
                return {
                    'status': 'healthy' if is_fresh else 'stale',
                    'latest_timestamp': latest_timestamp.isoformat(),
                    'age_minutes': round(age_minutes, 2)
                }
            else:
                return {
                    'status': 'no_data',
                    'error': 'No recent data found'
                }
                
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }
    
    def run_full_check(self) -> Dict:
        """è¿è¡Œå®Œæ•´çš„å¥åº·æ£€æŸ¥"""
        timestamp = datetime.utcnow().isoformat()
        
        checks = {
            'timestamp': timestamp,
            'redis': self.check_redis(),
            'postgres': self.check_postgres(),
            'influxdb': self.check_influxdb(),
            'grafana': self.check_grafana(),
            'data_freshness': self.check_data_freshness()
        }
        
        # è®¡ç®—æ•´ä½“çŠ¶æ€
        all_healthy = all(
            check.get('status') == 'healthy' 
            for check in checks.values() 
            if isinstance(check, dict) and 'status' in check
        )
        
        checks['overall_status'] = 'healthy' if all_healthy else 'unhealthy'
        
        return checks
```

#### æŒ‡æ ‡é‡‡é›†ç»„ä»¶

**apps/monitoring/metrics.py**
```python
"""
ä¸šåŠ¡æŒ‡æ ‡é‡‡é›†æ¨¡å—
å°†æŒ‡æ ‡å†™å…¥InfluxDBçš„ops bucket
"""
import os
import psutil
import time
from datetime import datetime
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS
import logging

class MetricsCollector:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.influx_client = InfluxDBClient(
            url=os.getenv('INFLUXDB_URL'),
            token=os.getenv('INFLUXDB_ADMIN_TOKEN'),
            org=os.getenv('INFLUXDB_ORG')
        )
        self.write_api = self.influx_client.write_api(write_options=SYNCHRONOUS)
        self.bucket = 'ops'  # è¿è¥æŒ‡æ ‡ä¸“ç”¨bucket
        
    def collect_system_metrics(self):
        """é‡‡é›†ç³»ç»Ÿèµ„æºæŒ‡æ ‡"""
        timestamp = datetime.utcnow()
        
        # CPUæŒ‡æ ‡
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        
        # å†…å­˜æŒ‡æ ‡
        memory = psutil.virtual_memory()
        
        # ç£ç›˜æŒ‡æ ‡
        disk = psutil.disk_usage('/')
        
        # ç½‘ç»œæŒ‡æ ‡
        network = psutil.net_io_counters()
        
        points = [
            Point("ops_system")
            .tag("metric_type", "cpu")
            .field("cpu_percent", cpu_percent)
            .field("cpu_count", cpu_count)
            .time(timestamp),
            
            Point("ops_system")
            .tag("metric_type", "memory")
            .field("memory_total", memory.total)
            .field("memory_used", memory.used)
            .field("memory_percent", memory.percent)
            .time(timestamp),
            
            Point("ops_system")
            .tag("metric_type", "disk")
            .field("disk_total", disk.total)
            .field("disk_used", disk.used)
            .field("disk_percent", disk.used / disk.total * 100)
            .time(timestamp),
            
            Point("ops_system")
            .tag("metric_type", "network")
            .field("bytes_sent", network.bytes_sent)
            .field("bytes_recv", network.bytes_recv)
            .field("packets_sent", network.packets_sent)
            .field("packets_recv", network.packets_recv)
            .time(timestamp)
        ]
        
        try:
            self.write_api.write(bucket=self.bucket, org=os.getenv('INFLUXDB_ORG'), record=points)
            self.logger.debug("System metrics collected successfully")
        except Exception as e:
            self.logger.error(f"Failed to write system metrics: {e}")
    
    def collect_data_quality_metrics(self):
        """é‡‡é›†æ•°æ®è´¨é‡æŒ‡æ ‡"""
        try:
            # æŸ¥è¯¢æœ€è¿‘1å°æ—¶çš„æ•°æ®ç‚¹æ•°é‡
            query = f'''
                from(bucket: "{os.getenv('INFLUXDB_BUCKET')}")
                |> range(start: -1h)
                |> filter(fn: (r) => r._measurement == "crypto_ohlcv_1m")
                |> group(columns: ["symbol"])
                |> count()
            '''
            
            tables = self.influx_client.query_api().query(query)
            timestamp = datetime.utcnow()
            
            points = []
            for table in tables:
                for record in table.records:
                    symbol = record.values.get('symbol', 'unknown')
                    count = record.get_value()
                    
                    point = Point("ops_data_quality") \
                        .tag("symbol", symbol) \
                        .tag("metric_type", "data_points_1h") \
                        .field("count", count) \
                        .time(timestamp)
                    points.append(point)
            
            if points:
                self.write_api.write(bucket=self.bucket, org=os.getenv('INFLUXDB_ORG'), record=points)
                self.logger.debug(f"Data quality metrics collected for {len(points)} symbols")
                
        except Exception as e:
            self.logger.error(f"Failed to collect data quality metrics: {e}")
    
    def collect_application_metrics(self, app_name: str, custom_metrics: Dict):
        """é‡‡é›†åº”ç”¨è‡ªå®šä¹‰æŒ‡æ ‡"""
        timestamp = datetime.utcnow()
        points = []
        
        for metric_name, value in custom_metrics.items():
            point = Point("ops_application") \
                .tag("app_name", app_name) \
                .tag("metric_name", metric_name) \
                .field("value", value) \
                .time(timestamp)
            points.append(point)
        
        try:
            self.write_api.write(bucket=self.bucket, org=os.getenv('INFLUXDB_ORG'), record=points)
            self.logger.debug(f"Application metrics collected for {app_name}")
        except Exception as e:
            self.logger.error(f"Failed to write application metrics: {e}")
```

#### å‘Šè­¦ç»„ä»¶

**apps/monitoring/bark_notifier.py**
```python
"""
Bark æ¨é€é€šçŸ¥æ¨¡å—
"""
import os
import json
import yaml
import requests
from datetime import datetime
from typing import Dict, List
import logging

class BarkNotifier:
    def __init__(self, config_path="/config/alerts.yml"):
        self.logger = logging.getLogger(__name__)
        
        # åŠ è½½å‘Šè­¦é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
            
        self.bark_config = self.config['bark']
        self.base_url = self.bark_config['server']['base_url']
        self.push_key = self.bark_config['push_key']
        
    def send_notification(self, alert: Dict):
        """å‘é€ Bark æ¨é€é€šçŸ¥"""
        try:
            severity = alert.get('severity', 'medium')
            severity_config = self.bark_config['severity_config'].get(severity, {})
            
            # æ„å»ºæ¨é€æ¶ˆæ¯
            title = f"ğŸš¨ {alert['title']}"
            body = self._format_message(alert)
            
            # æ„å»ºæ¨é€URL
            url = f"{self.base_url}/{self.push_key}/{title}/{body}"
            
            # æ·»åŠ æ¨é€å‚æ•°
            params = {
                'group': self.bark_config['default_config']['group'],
                'icon': self.bark_config['default_config']['icon'],
                'sound': severity_config.get('sound', 'default'),
                'level': severity_config.get('level', 'active')
            }
            
            # ä¸¥é‡å‘Šè­¦ç‰¹æ®Šå¤„ç†
            if severity == 'critical':
                if severity_config.get('call'):
                    params['call'] = '1'
                    
            # å‘é€æ¨é€
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                if result.get('code') == 200:
                    self.logger.info(f"Bark notification sent successfully: {alert['title']}")
                    return True
                else:
                    self.logger.error(f"Bark API error: {result.get('message')}")
                    return False
            else:
                self.logger.error(f"Bark HTTP error: {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"Failed to send Bark notification: {e}")
            return False
    
    def _format_message(self, alert: Dict) -> str:
        """æ ¼å¼åŒ–å‘Šè­¦æ¶ˆæ¯"""
        severity_emojis = {
            'critical': 'ğŸ”´',
            'high': 'ğŸŸ ',
            'medium': 'ğŸŸ¡',
            'low': 'ğŸ”µ'
        }
        
        severity = alert.get('severity', 'medium')
        emoji = severity_emojis.get(severity, 'âšª')
        
        message = f"{emoji} {alert.get('message', '')}\n"
        message += f"ğŸ“Š ç»„ä»¶: {alert.get('component', 'Unknown')}\n"
        message += f"â° æ—¶é—´: {alert.get('timestamp', datetime.utcnow().isoformat())}\n"
        
        if alert.get('details'):
            message += f"ğŸ“ è¯¦æƒ…: {json.dumps(alert['details'], ensure_ascii=False, indent=2)}"
            
        return message
    
    def test_notification(self):
        """æµ‹è¯• Bark è¿é€šæ€§"""
        test_alert = {
            'title': 'AlgorithmTrader æµ‹è¯•é€šçŸ¥',
            'message': 'ç³»ç»Ÿå‘Šè­¦åŠŸèƒ½æ­£å¸¸å·¥ä½œ',
            'severity': 'low',
            'component': 'monitoring',
            'timestamp': datetime.utcnow().isoformat()
        }
        
        return self.send_notification(test_alert)
```

**apps/monitoring/alerts.py**
```python
"""
å‘Šè­¦å¤„ç†æ¨¡å— - ä½¿ç”¨ Bark æ¨é€
"""
import os
import yaml
import json
from datetime import datetime, timedelta
from typing import Dict, List
import logging

from .bark_notifier import BarkNotifier

class AlertManager:
    def __init__(self, config_path="/config/alerts.yml"):
        self.logger = logging.getLogger(__name__)
        
        # åŠ è½½é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
            
        self.bark_notifier = BarkNotifier(config_path)
        self.alert_history = []
        self.suppression_cache = {}
        
    def check_alert_rules(self, metrics_data: Dict) -> List[Dict]:
        """æ£€æŸ¥å‘Šè­¦è§„åˆ™"""
        alerts = []
        
        # ç³»ç»Ÿçº§å‘Šè­¦æ£€æŸ¥
        alerts.extend(self._check_system_alerts(metrics_data))
        
        # æœåŠ¡çº§å‘Šè­¦æ£€æŸ¥
        alerts.extend(self._check_service_alerts(metrics_data))
        
        # æ•°æ®è´¨é‡å‘Šè­¦æ£€æŸ¥
        alerts.extend(self._check_data_quality_alerts(metrics_data))
        
        # ä¸šåŠ¡çº§å‘Šè­¦æ£€æŸ¥
        alerts.extend(self._check_business_alerts(metrics_data))
        
        return alerts
    
    def _check_system_alerts(self, data: Dict) -> List[Dict]:
        """æ£€æŸ¥ç³»ç»Ÿçº§å‘Šè­¦"""
        alerts = []
        rules = self.config['alert_rules']['system_alerts']
        
        # CPUä½¿ç”¨ç‡æ£€æŸ¥
        cpu_usage = data.get('cpu_percent', 0)
        if cpu_usage > 90:
            alerts.append(self._create_alert(
                'cpu_usage_critical',
                f"CPUä½¿ç”¨ç‡ä¸¥é‡: {cpu_usage}%",
                'critical',
                'system',
                {'cpu_usage': cpu_usage}
            ))
        elif cpu_usage > 80:
            alerts.append(self._create_alert(
                'cpu_usage_high',
                f"CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_usage}%",
                'high',
                'system',
                {'cpu_usage': cpu_usage}
            ))
        
        # å†…å­˜ä½¿ç”¨ç‡æ£€æŸ¥
        memory_usage = data.get('memory_percent', 0)
        if memory_usage > 95:
            alerts.append(self._create_alert(
                'memory_usage_critical',
                f"å†…å­˜ä½¿ç”¨ç‡ä¸¥é‡: {memory_usage}%",
                'critical',
                'system',
                {'memory_usage': memory_usage}
            ))
        elif memory_usage > 85:
            alerts.append(self._create_alert(
                'memory_usage_high',
                f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_usage}%",
                'high',
                'system',
                {'memory_usage': memory_usage}
            ))
        
        return alerts
    
    def _check_service_alerts(self, data: Dict) -> List[Dict]:
        """æ£€æŸ¥æœåŠ¡çº§å‘Šè­¦"""
        alerts = []
        
        # æ£€æŸ¥å„æœåŠ¡å¥åº·çŠ¶æ€
        services = ['influxdb', 'redis', 'postgres', 'grafana']
        for service in services:
            status = data.get(f'{service}_status')
            if status and status != 'healthy':
                severity = 'critical' if service == 'influxdb' else 'high'
                alerts.append(self._create_alert(
                    f'{service}_down',
                    f"{service.upper()}æœåŠ¡å¼‚å¸¸",
                    severity,
                    service,
                    {'status': status, 'error': data.get(f'{service}_error')}
                ))
        
        return alerts
    
    def _check_data_quality_alerts(self, data: Dict) -> List[Dict]:
        """æ£€æŸ¥æ•°æ®è´¨é‡å‘Šè­¦"""
        alerts = []
        
        # æ•°æ®æ–°é²œåº¦æ£€æŸ¥
        data_age = data.get('data_age_minutes', 0)
        if data_age > 180:
            alerts.append(self._create_alert(
                'data_very_stale',
                f"å¸‚åœºæ•°æ®ä¸¥é‡å»¶è¿Ÿ: {data_age}åˆ†é’Ÿæœªæ›´æ–°",
                'critical',
                'data_quality',
                {'age_minutes': data_age}
            ))
        elif data_age > 60:
            alerts.append(self._create_alert(
                'data_stale',
                f"å¸‚åœºæ•°æ®å»¶è¿Ÿ: {data_age}åˆ†é’Ÿæœªæ›´æ–°",
                'high',
                'data_quality',
                {'age_minutes': data_age}
            ))
        
        return alerts
    
    def _check_business_alerts(self, data: Dict) -> List[Dict]:
        """æ£€æŸ¥ä¸šåŠ¡çº§å‘Šè­¦"""
        alerts = []
        
        # å›æ’¤æ£€æŸ¥
        drawdown = data.get('drawdown_percent', 0)
        if drawdown > 15:
            alerts.append(self._create_alert(
                'portfolio_drawdown_critical',
                f"ç»„åˆå›æ’¤ä¸¥é‡: {drawdown}%",
                'critical',
                'portfolio',
                {'drawdown': drawdown}
            ))
        elif drawdown > 10:
            alerts.append(self._create_alert(
                'portfolio_drawdown_high',
                f"ç»„åˆå›æ’¤è¿‡é«˜: {drawdown}%",
                'high',
                'portfolio',
                {'drawdown': drawdown}
            ))
        
        return alerts
    
    def _create_alert(self, name: str, message: str, severity: str, 
                     component: str, details: Dict) -> Dict:
        """åˆ›å»ºå‘Šè­¦å¯¹è±¡"""
        return {
            'name': name,
            'title': name.replace('_', ' ').title(),
            'message': message,
            'severity': severity,
            'component': component,
            'timestamp': datetime.utcnow().isoformat(),
            'details': details
        }
    
    def process_alerts(self, alerts: List[Dict]):
        """å¤„ç†å‘Šè­¦åˆ—è¡¨"""
        for alert in alerts:
            # æ£€æŸ¥å‘Šè­¦æŠ‘åˆ¶
            if self._should_suppress(alert):
                self.logger.debug(f"Alert suppressed: {alert['name']}")
                continue
                
            # è®°å½•å‘Šè­¦å†å²
            self.alert_history.append(alert)
            
            # å‘é€é€šçŸ¥
            success = self.bark_notifier.send_notification(alert)
            
            if success:
                self.logger.info(f"Alert processed: {alert['name']}")
                # æ›´æ–°æŠ‘åˆ¶ç¼“å­˜
                self._update_suppression_cache(alert)
            else:
                self.logger.error(f"Failed to send alert: {alert['name']}")
    
    def _should_suppress(self, alert: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æŠ‘åˆ¶å‘Šè­¦"""
        alert_key = f"{alert['component']}_{alert['name']}"
        suppression_time = self.config['global']['suppression_time']
        
        if alert_key in self.suppression_cache:
            last_sent = self.suppression_cache[alert_key]
            if (datetime.utcnow() - last_sent).total_seconds() < suppression_time:
                return True
                
        return False
    
    def _update_suppression_cache(self, alert: Dict):
        """æ›´æ–°å‘Šè­¦æŠ‘åˆ¶ç¼“å­˜"""
        alert_key = f"{alert['component']}_{alert['name']}"
        self.suppression_cache[alert_key] = datetime.utcnow()
```

### 5.2 åˆ›å»ºç›‘æ§ä¸»ç¨‹åº

**apps/monitoring/main.py**
```python
"""
ç›‘æ§ä¸»ç¨‹åº
å®šæœŸè¿è¡Œå¥åº·æ£€æŸ¥å’ŒæŒ‡æ ‡é‡‡é›†ï¼Œä½¿ç”¨YAMLé…ç½®æ–‡ä»¶
"""
import os
import time
import json
import yaml
import logging
from datetime import datetime

from health_check import HealthChecker
from metrics import MetricsCollector
from alerts import AlertManager

def load_config(config_path="/config/monitoring.yml"):
    """åŠ è½½ç›‘æ§é…ç½®"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def setup_logging(config):
    """é…ç½®æ—¥å¿—"""
    log_level = config['logging']['level']
    log_format = config['logging']['format']
    
    logging.basicConfig(
        level=getattr(logging, log_level),
        format=log_format,
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('/var/log/monitoring.log')
        ]
    )

def main():
    # åŠ è½½é…ç½®
    config = load_config()
    setup_logging(config)
    
    logger = logging.getLogger(__name__)
    
    # åˆå§‹åŒ–ç»„ä»¶
    health_checker = HealthChecker()
    metrics_collector = MetricsCollector()
    alert_manager = AlertManager()
    
    # ç›‘æ§é—´éš”(ç§’)
    interval = config['global']['check_interval']
    
    logger.info("Monitoring system started with config-driven approach")
    
    while True:
        try:
            start_time = time.time()
            
            # è¿è¡Œå¥åº·æ£€æŸ¥
            health_data = health_checker.run_full_check()
            logger.info(f"Health check completed: {health_data['overall_status']}")
            
            # é‡‡é›†ç³»ç»ŸæŒ‡æ ‡
            metrics_collector.collect_system_metrics()
            
            # é‡‡é›†æ•°æ®è´¨é‡æŒ‡æ ‡
            metrics_collector.collect_data_quality_metrics()
            
            # æ£€æŸ¥å‘Šè­¦è§„åˆ™
            alerts = alert_manager.check_alert_rules(health_data)
            if alerts:
                alert_manager.process_alerts(alerts)
            
            # è®°å½•ç›‘æ§ç³»ç»Ÿè‡ªèº«çš„æŒ‡æ ‡
            execution_time = time.time() - start_time
            metrics_collector.collect_application_metrics('monitoring', {
                'execution_time_seconds': execution_time,
                'alerts_generated': len(alerts),
                'health_check_duration': execution_time
            })
            
            # ä¿å­˜å¥åº·æ£€æŸ¥ç»“æœåˆ°æ–‡ä»¶
            with open('/tmp/health_status.json', 'w') as f:
                json.dump(health_data, f, indent=2, default=str)
            
            # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
            time.sleep(max(0, interval - execution_time))
            
        except KeyboardInterrupt:
            logger.info("Monitoring stopped by user")
            break
        except Exception as e:
            logger.error(f"Monitoring error: {e}", exc_info=True)
            time.sleep(interval)

if __name__ == "__main__":
    main()
```

### 5.3 DockeråŒ–ç›‘æ§æœåŠ¡

**apps/monitoring/Dockerfile**
```dockerfile
FROM python:3.11-slim

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    procps \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# åˆ›å»ºæ—¥å¿—ç›®å½•
RUN mkdir -p /var/log

ENV PYTHONPATH=/app
ENV TZ=UTC

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD python -c "import json; print(json.load(open('/tmp/health_status.json'))['overall_status'])" || exit 1

CMD ["python", "main.py"]
```

**apps/monitoring/requirements.txt**
```
psutil>=5.9.0
redis>=4.5.0
psycopg2-binary>=2.9.0
influxdb-client>=1.36.0
requests>=2.31.0
PyYAML>=6.0
```

### 5.4 æ›´æ–°Docker Composeé…ç½®

åœ¨ `docker-compose.yml` ä¸­æ·»åŠ ç›‘æ§æœåŠ¡ï¼š

```yaml
  monitoring:
    build: ./apps/monitoring
    container_name: ${COMPOSE_PROJECT_NAME:-algorithmtrader}-monitoring
    profiles: ["apps"]
    restart: unless-stopped
    environment:
      - TZ=${TZ:-UTC}
      - INFLUXDB_URL=${INFLUXDB_URL}
      - INFLUXDB_ADMIN_TOKEN=${INFLUXDB_ADMIN_TOKEN}
      - INFLUXDB_ORG=${INFLUXDB_ORG}
      - REDIS_URL=${REDIS_URL}
      - POSTGRES_URL=${POSTGRES_URL}
      - GRAFANA_PORT=${GRAFANA_PORT}
    volumes:
      - /var/log/algorithmtrader:/var/log
      - ./config:/config:ro    # æŒ‚è½½é…ç½®æ–‡ä»¶ç›®å½•(åªè¯»)
    depends_on:
      - influxdb
      - redis
      - postgres
      - grafana
    networks:
      - quant-net
```

### 5.5 åˆ›å»ºç³»ç»Ÿå¥åº·é¢æ¿

åœ¨Grafanaä¸­åˆ›å»ºç³»ç»Ÿç›‘æ§é¢æ¿ï¼š

#### é¢æ¿1: æœåŠ¡çŠ¶æ€æ¦‚è§ˆ
```flux
from(bucket: "ops")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r._measurement == "ops_system")
  |> filter(fn: (r) => r._field == "cpu_percent" or r._field == "memory_percent")
  |> aggregateWindow(every: v.windowPeriod, fn: mean)
```

#### é¢æ¿2: æ•°æ®è´¨é‡ç›‘æ§
```flux
from(bucket: "ops")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r._measurement == "ops_data_quality")
  |> filter(fn: (r) => r._field == "count")
  |> group(columns: ["symbol"])
```

#### é¢æ¿3: å‘Šè­¦å†å²
æ˜¾ç¤ºæœ€è¿‘çš„å‘Šè­¦äº‹ä»¶å’Œç³»ç»ŸçŠ¶æ€å˜åŒ–

### 5.6 è®¾ç½®Grafanaå‘Šè­¦è§„åˆ™

1. åœ¨Grafanaä¸­åˆ›å»ºå‘Šè­¦è§„åˆ™ï¼š
   - CPUä½¿ç”¨ç‡ > 80%
   - å†…å­˜ä½¿ç”¨ç‡ > 90%
   - ç£ç›˜ä½¿ç”¨ç‡ > 85%
   - æ•°æ®è¶…è¿‡1å°æ—¶æœªæ›´æ–°

2. é…ç½®é€šçŸ¥æ¸ é“ï¼š
   - é‚®ä»¶é€šçŸ¥
   - Webhooké€šçŸ¥ï¼ˆå¯é€‰ï¼‰

### 5.7 å¯åŠ¨ç›‘æ§æœåŠ¡

```bash
# å¯åŠ¨ç›‘æ§æœåŠ¡
docker-compose --profile apps up -d monitoring

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps monitoring

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f monitoring
```

## éªŒæ”¶æ ‡å‡†

### å¥åº·æ£€æŸ¥
- [ ] æ‰€æœ‰ç»„ä»¶å¥åº·çŠ¶æ€æ£€æŸ¥æ­£å¸¸
- [ ] è¿æ¥å»¶è¿Ÿæµ‹è¯•é€šè¿‡
- [ ] æ•°æ®æ–°é²œåº¦æ£€æŸ¥å‡†ç¡®
- [ ] å¥åº·çŠ¶æ€æ–‡ä»¶æ­£ç¡®è¾“å‡º

### æŒ‡æ ‡é‡‡é›†
- [ ] ç³»ç»Ÿèµ„æºæŒ‡æ ‡æ­£ç¡®é‡‡é›†
- [ ] æ•°æ®è´¨é‡æŒ‡æ ‡å‡†ç¡®
- [ ] åº”ç”¨è‡ªå®šä¹‰æŒ‡æ ‡æ­£å¸¸
- [ ] InfluxDBå†™å…¥æˆåŠŸ

### å‘Šè­¦åŠŸèƒ½
- [ ] å‘Šè­¦è§„åˆ™è§¦å‘æ­£ç¡®
- [ ] é‚®ä»¶é€šçŸ¥å‘é€æˆåŠŸ
- [ ] å‘Šè­¦æ—¥å¿—è®°å½•å®Œæ•´
- [ ] å‘Šè­¦æŠ‘åˆ¶æœºåˆ¶å·¥ä½œ

### å¯è§†åŒ–
- [ ] Grafanaç›‘æ§é¢æ¿æ˜¾ç¤ºæ­£ç¡®
- [ ] å‘Šè­¦è§„åˆ™é…ç½®ç”Ÿæ•ˆ
- [ ] é€šçŸ¥æ¸ é“æµ‹è¯•é€šè¿‡
- [ ] å†å²æ•°æ®æŸ¥è¯¢æ­£å¸¸

## æ•…éšœæ’é™¤

### å¥åº·æ£€æŸ¥é—®é¢˜
```bash
# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
docker exec algorithmtrader-monitoring ping influxdb
docker exec algorithmtrader-monitoring ping redis
docker exec algorithmtrader-monitoring ping postgres

# æ£€æŸ¥æœåŠ¡ç«¯å£
docker exec algorithmtrader-monitoring netstat -tulpn
```

### æŒ‡æ ‡é‡‡é›†é—®é¢˜
```bash
# æ£€æŸ¥InfluxDB ops bucket
docker exec algorithmtrader-influxdb influx bucket list

# åˆ›å»ºops bucket(å¦‚æœä¸å­˜åœ¨)
docker exec algorithmtrader-influxdb influx bucket create --name ops --org quant --retention 8760h

# éªŒè¯æŒ‡æ ‡å†™å…¥
docker exec algorithmtrader-influxdb influx query 'from(bucket: "ops") |> range(start: -1h) |> count()'
```

### å‘Šè­¦é—®é¢˜
```bash
# æµ‹è¯• Bark æ¨é€
python -c "
from apps.monitoring.bark_notifier import BarkNotifier

notifier = BarkNotifier()
test_result = notifier.test_notification()
print(f'Bark test result: {test_result}')
"

# æ£€æŸ¥é…ç½®æ–‡ä»¶
cat config/alerts.yml | grep -A 10 bark

# æµ‹è¯•å‘Šè­¦è§„åˆ™
python -c "
from apps.monitoring.alerts import AlertManager

alert_manager = AlertManager()
test_data = {'cpu_percent': 95, 'memory_percent': 88}
alerts = alert_manager.check_alert_rules(test_data)
print(f'Generated {len(alerts)} alerts')
for alert in alerts:
    print(f'- {alert[\"name\"]}: {alert[\"message\"]}')
"
```

### Grafanaé—®é¢˜
```bash
# æ£€æŸ¥æ•°æ®æºé…ç½®
curl -u admin:password http://localhost:3000/api/datasources

# æµ‹è¯•FluxæŸ¥è¯¢
curl -u admin:password \
  -XPOST http://localhost:3000/api/ds/query \
  -H "Content-Type: application/json" \
  -d '{"queries":[{"datasource":{"uid":"influxdb"},"refId":"A","query":"from(bucket: \"ops\") |> range(start: -1h) |> limit(n: 10)"}]}'
```

## å®ŒæˆMVP

æ­å–œï¼å®ŒæˆPhase 5åï¼Œæ‚¨çš„åŠ å¯†è´§å¸é‡åŒ–äº¤æ˜“ç³»ç»ŸMVPå·²ç»æ­å»ºå®Œæˆã€‚

**ç³»ç»ŸåŠŸèƒ½æ¦‚è§ˆ**:
âœ… **æ•°æ®é‡‡é›†**: BTC/ETHå†å²æ•°æ®ä¸‹è½½å’Œå­˜å‚¨  
âœ… **æ•°æ®å­˜å‚¨**: InfluxDBæ—¶åºæ•°æ®åº“ + Parquetæ•°æ®æ¹–  
âœ… **æ•°æ®å¯è§†åŒ–**: Grafanaä»ªè¡¨ç›˜å±•ç¤ºå¸‚åœºæ•°æ®  
âœ… **ç­–ç•¥å¼•æ“**: åŒå‡çº¿ç­–ç•¥å®ç°å’Œå›æµ‹  
âœ… **ç›‘æ§å‘Šè­¦**: å®Œæ•´çš„ç³»ç»Ÿç›‘æ§å’Œå‘Šè­¦æœºåˆ¶  

**ä¸‹ä¸€æ­¥æ‰©å±•å»ºè®®**:
1. æ·»åŠ æ›´å¤šæŠ€æœ¯æŒ‡æ ‡å’Œç­–ç•¥
2. æ¥å…¥å®æ—¶æ•°æ®æµ
3. æ‰©å±•åˆ°æ›´å¤šäº¤æ˜“å¯¹
4. å®ç°é£é™©ç®¡ç†æ¨¡å—
5. å‡†å¤‡å®ç›˜äº¤æ˜“æ¥å£

ç³»ç»Ÿç°åœ¨å¯ä»¥ä½œä¸ºå­¦ä¹ å’Œå®éªŒå¹³å°ï¼Œä¸ºåç»­çš„åŠŸèƒ½æ‰©å±•æ‰“ä¸‹åšå®åŸºç¡€ã€‚
